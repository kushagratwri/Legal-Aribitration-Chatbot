{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from sec_edgar_downloader import Downloader\n",
    "from huggingface_hub import login, notebook_login\n",
    "from smolagents import Tool, HfApiModel, ToolCallingAgent\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a149937dec43108265ae553200b9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# 1. Data Fetcher: Currently using sec filings as an example, replace with your own data source\n",
    "########################################################################################################################\n",
    "\n",
    "class SECDataFetcher:\n",
    "    def __init__(self, storage_dir=\"./sec_filings\"):\n",
    "        self.downloader = Downloader(email_address=\"jjbigdub@gmail.com\", company_name=\"FAC-IITK\", download_folder=storage_dir)\n",
    "\n",
    "    def fetch_filings(self, cik: str, form_type: str = \"10-Q\"):\n",
    "        filings = self.downloader.get(form_type, cik, limit=1)\n",
    "        return filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################################################\n",
    "# 2. Extraction Agent: Preprocess the extracted data, can make multiple preprocessing functions depending on the structure of the fetched data\n",
    "#################################################################################################################################################\n",
    "\n",
    "class TabularDataAgent(Tool):\n",
    "    name = \"tabular_data_extractor\"\n",
    "    description = (\n",
    "        \"Extracts and intelligently identifies relevant numerical financial data from an SEC 10-Q filing. \"\n",
    "        \"If multiple distinct tabular datasets exist within the document, output them as a JSON array; \"\n",
    "        \"each element must be an object with two keys: 'table' (a Markdown formatted table with two columns, \"\n",
    "        \"'Financial Metric' and 'Value') and 'context' (detailed excerpts or explanation of where the numbers were found). \"\n",
    "        \"Do not include any commentary outside of the JSON object.\"\n",
    "    )\n",
    "    inputs = {\n",
    "        \"file_path\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The file path of the SEC 10-Q filing document.\"\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, file_path: str) -> str:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                content = f.read()\n",
    "        except Exception as e:\n",
    "            return json.dumps([{\"table\": \"\", \"context\": f\"Error reading file: {e}\"}])\n",
    "        \n",
    "        prompt = (\n",
    "            \"You are an expert financial analyst and data scientist. \"\n",
    "            \"You are given the full text of an unstructured SEC 10-Q filing that may have numerical values scattered randomly. \"\n",
    "            \"Your task is to intelligently identify which numerical values are relevant to the financial statements, \"\n",
    "            \"capture the context (e.g., surrounding sentences or paragraphs) for each value, and output the results as a JSON array. \"\n",
    "            \"Each element of the array must be an object with exactly two keys: 'table' and 'context'. \"\n",
    "            \"The 'table' must be a Markdown formatted table with two columns: 'Financial Metric' and 'Value'. \"\n",
    "            \"If only one dataset is found, output it as an array with a single object. Do not include any extra commentary.\\n\\n\"\n",
    "            \"SEC 10-Q Filing Content:\\n\"\n",
    "            f\"{content}\\n\"\n",
    "        )\n",
    "        prompt_message = {\"role\": \"user\", \"content\": prompt}\n",
    "        raw_result = self.model([prompt_message])\n",
    "        return raw_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 3. Evaluation Agent for Tabular Data Format\n",
    "############################################################\n",
    "\n",
    "class EvaluateAgent(Tool):\n",
    "    name = \"evaluate_tabular_data\"\n",
    "    description = (\n",
    "        \"Evaluates and corrects the format of a JSON output from a tabular data extraction. \"\n",
    "        \"Ensure that the output is a JSON array of objects, where each object has exactly two keys: \"\n",
    "        \"'table' and 'context'. Return a corrected JSON string if necessary.\"\n",
    "    )\n",
    "    inputs = {\n",
    "        \"extraction_output\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The JSON string output from the extraction tool.\"\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, extraction_output: str) -> str:\n",
    "        prompt = (\n",
    "            \"You are an expert in data formatting. Validate the following JSON data to ensure that it is a JSON array \"\n",
    "            \"of objects, where each object has exactly two keys: 'table' and 'context'. If it is not correctly formatted, \"\n",
    "            \"return a corrected JSON string. Otherwise, return the input unchanged.\\n\\n\"\n",
    "            f\"Input JSON:\\n{extraction_output}\\n\"\n",
    "        )\n",
    "        prompt_message = {\"role\": \"user\", \"content\": prompt}\n",
    "        result = self.run([prompt_message])\n",
    "        try:\n",
    "            json.loads(result)\n",
    "            return result\n",
    "        except Exception:\n",
    "            return extraction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 4. Query Tool to Search the Vector Database\n",
    "############################################################\n",
    "\n",
    "class QueryVectorDBTool(Tool):\n",
    "    name = \"query_vector_db\"\n",
    "    description = (\n",
    "        \"Queries the vector database to retrieve stored financial data. \"\n",
    "        \"Input a natural language query and return the most relevant documents, each containing a Markdown table and detailed context.\"\n",
    "    )\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A natural language query to search the vector database.\"\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, vectordb, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.vectordb = vectordb\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        docs = self.vectordb.similarity_search(query, k=5)\n",
    "        results = []\n",
    "        for i, doc in enumerate(docs):\n",
    "            results.append(\n",
    "                f\"Document {i} (Source: {doc.metadata.get('source', 'N/A')}):\\n{doc.page_content}\\n\"\n",
    "            )\n",
    "        return \"\\n\".join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "(Request ID: KsXe--)\n\nBad request:\nModel requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/meta-llama/Llama-3.1-70B-Instruct/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m documents \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filing \u001b[38;5;129;01min\u001b[39;00m filings:\n\u001b[0;32m---> 21\u001b[0m     extraction_result \u001b[38;5;241m=\u001b[39m \u001b[43mextraction_tool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     evaluated_result \u001b[38;5;241m=\u001b[39m evaluation_tool\u001b[38;5;241m.\u001b[39mforward(extraction_result)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[13], line 45\u001b[0m, in \u001b[0;36mTabularDataAgent.forward\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m     33\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert financial analyst and data scientist. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are given the full text of an unstructured SEC 10-Q filing that may have numerical values scattered randomly. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m prompt_message \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}\n\u001b[0;32m---> 45\u001b[0m raw_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt_message\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m raw_result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/smolagents/models.py:408\u001b[0m, in \u001b[0;36mHfApiModel.__call__\u001b[0;34m(self, messages, stop_sequences, grammar, tools_to_call_from, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    393\u001b[0m     messages: List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatMessage:\n\u001b[1;32m    399\u001b[0m     completion_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_completion_kwargs(\n\u001b[1;32m    400\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    401\u001b[0m         stop_sequences\u001b[38;5;241m=\u001b[39mstop_sequences,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    407\u001b[0m     )\n\u001b[0;32m--> 408\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_input_token_count \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39musage\u001b[38;5;241m.\u001b[39mprompt_tokens\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_output_token_count \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39musage\u001b[38;5;241m.\u001b[39mcompletion_tokens\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:970\u001b[0m, in \u001b[0;36mInferenceClient.chat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p)\u001b[0m\n\u001b[1;32m    943\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: payload_model,\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    962\u001b[0m }\n\u001b[1;32m    963\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[1;32m    964\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    965\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    968\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m    969\u001b[0m )\n\u001b[0;32m--> 970\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:327\u001b[0m, in \u001b[0;36mInferenceClient._inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:460\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    457\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m     )\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(BadRequestError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    463\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure your token has the correct permissions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m     )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: (Request ID: KsXe--)\n\nBad request:\nModel requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query."
     ]
    }
   ],
   "source": [
    "sec_fetcher = SECDataFetcher(storage_dir=\"./sec_filings\")\n",
    "cik = \"0000320193\"  \n",
    "sec_fetcher.fetch_filings(cik=cik, form_type=\"10-Q\")\n",
    "\n",
    "parent_folder = os.path.join(\"./sec_filings\", \"sec-edgar-filings\", cik, \"10-Q\")\n",
    "\n",
    "filings = []\n",
    "for root, dirs, files in os.walk(parent_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            filings.append(os.path.join(root, file))\n",
    "\n",
    "#print(filings)\n",
    "\n",
    "model = HfApiModel(\"meta-llama/Llama-3.1-70B-Instruct\")\n",
    "extraction_tool = TabularDataAgent(model=model)\n",
    "evaluation_tool = EvaluateAgent(model=model)\n",
    "\n",
    "documents = []\n",
    "for filing in filings:\n",
    "    extraction_result = extraction_tool.forward(filing)\n",
    "    evaluated_result = evaluation_tool.forward(extraction_result)\n",
    "    try:\n",
    "        extraction_data = json.loads(evaluated_result)\n",
    "        if not isinstance(extraction_data, list):\n",
    "            extraction_data = [extraction_data]\n",
    "    except Exception as e:\n",
    "        extraction_data = [{\"table\": extraction_result, \"context\": f\"Parsing error: {e}\"}]\n",
    "\n",
    "    for dataset in extraction_data:\n",
    "        table = dataset.get(\"table\", \"\")\n",
    "        context_detail = dataset.get(\"context\", \"\")\n",
    "        combined_content = f\"Table:\\n{table}\\n\\nDetailed Context:\\n{context_detail}\"\n",
    "        doc = Document(page_content=combined_content, metadata={\"source\": filing, \"cik\": cik})\n",
    "        documents.append(doc)\n",
    "        print(f\"Stored dataset from filing: {filing}\\n{'-'*40}\\n{combined_content}\\n{'='*40}\\n\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    ")\n",
    "\n",
    "query_tool = QueryVectorDBTool(vectordb=vectordb)\n",
    "agent = ToolCallingAgent(tools=[query_tool], model=model)\n",
    "\n",
    "query = \"Show me financial metrics related to revenue and net income.\"\n",
    "query_result = agent.run(query)\n",
    "print(\"Query Result:\\n\", query_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
